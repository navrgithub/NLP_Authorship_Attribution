{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/navrgithub/NLP_Authorship_Attribution/blob/main/ngram%2Broberta%2Bcnn_task3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvSFBhiBxHky",
        "outputId": "5941b87a-c3db-493c-f0be-1e4260cbbfb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "TUToFr9shwth",
        "outputId": "b373aed1-5a74-45af-9b4f-f8fd32977d03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive/Colab Notebooks/NLP group project/data')"
      ],
      "metadata": {
        "id": "qV-sQ0G3hzWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyPQgvyr-OfJ"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import pandas as pd \n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odkUNjbxjJhV",
        "outputId": "e973e5cb-9036-43eb-a03f-3223863b9284"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Unnamed: 0                                               text  label\n",
            "0               0  CMV: Fat Acceptance Tik Tokers and influencers...      0\n",
            "1               1  CMV: It makes sense to compare apples and oranges      0\n",
            "2               2  CMV: Dismissing an individual's experience bec...      0\n",
            "3               3  CMV: If pro-anorexia groups, suicide promotion...      0\n",
            "4               4  CMV: Asian Americans generally prospering in t...      0\n",
            "...           ...                                                ...    ...\n",
            "12336        1061  how much of your body is your own? if i'm not ...      1\n",
            "12337        1062  how do you keep a space station clean? the ast...      1\n",
            "12338        1063  the city where you pay a year's rent up front,...      1\n",
            "12339        1064  the bbc app gives you the best of bbc wherever...      1\n",
            "12340        1065  learn how the bbc is working to strengthen tru...      1\n",
            "\n",
            "[12341 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df_nw= pd.read_csv(\"final_task3_data.csv\")\n",
        "print(df_nw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wiqZOXhPC5q"
      },
      "outputs": [],
      "source": [
        "df = df_nw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8R5REtsP_aO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2023b2e-c3b7-4992-bd23-bf3ad548293c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Unnamed: 0                                               text  label\n",
            "0               0  CMV: Fat Acceptance Tik Tokers and influencers...      0\n",
            "1               1  CMV: It makes sense to compare apples and oranges      0\n",
            "2               2  CMV: Dismissing an individual's experience bec...      0\n",
            "3               3  CMV: If pro-anorexia groups, suicide promotion...      0\n",
            "4               4  CMV: Asian Americans generally prospering in t...      0\n",
            "...           ...                                                ...    ...\n",
            "12336        1061  how much of your body is your own? if i'm not ...      1\n",
            "12337        1062  how do you keep a space station clean? the ast...      1\n",
            "12338        1063  the city where you pay a year's rent up front,...      1\n",
            "12339        1064  the bbc app gives you the best of bbc wherever...      1\n",
            "12340        1065  learn how the bbc is working to strengthen tru...      1\n",
            "\n",
            "[12341 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "df_nw['text'].fillna('', inplace=True)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame\n",
        "# Rename column 'B' to 'new_name'\n",
        "df = df.rename(columns={'Generation': 'text'})\n",
        "\n",
        "print(df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "\n",
        "# Define the n-gram size\n",
        "n = 3\n",
        "\n",
        "# Define the number of classes\n",
        "num_classes = 2\n"
      ],
      "metadata": {
        "id": "Oz0Y9rkwgQD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the PyTorch device to use\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the data frame\n",
        "# Split the data into training and validation sets\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n"
      ],
      "metadata": {
        "id": "UZQDNJCDhNdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a tokenizer function that converts text to n-gram word embeddings\n",
        "def tokenize(text):\n",
        "    tokens = []\n",
        "    for i in range(len(text) - n + 1):\n",
        "        tokens.append(text[i:i+n])\n",
        "    return tokens\n"
      ],
      "metadata": {
        "id": "OQfPTlkfhNuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a custom dataset class\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        text = self.df.iloc[idx][\"text\"]\n",
        "        label = self.df.iloc[idx][\"label\"]\n",
        "        tokenized_text = tokenize(text)\n",
        "        return tokenized_text, label"
      ],
      "metadata": {
        "id": "FxIA8aZ0hN1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the combined Roberta and CNN model\n",
        "class RobertaCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RobertaCNN, self).__init__()\n",
        "        self.roberta = torch.hub.load('pytorch/fairseq', 'roberta.large')\n",
        "        self.cnn = nn.Conv1d(in_channels=1024, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.fc = nn.Linear(64, num_classes)\n",
        "        \n",
        "    def forward(self, tokens):\n",
        "        # Convert tokens to Roberta embeddings\n",
        "        embeddings = self.roberta.extract_features(tokens)\n",
        "        # Convert embeddings to CNN input format\n",
        "        embeddings = embeddings.transpose(1, 2)\n",
        "        # Apply CNN layer\n",
        "        cnn_output = self.cnn(embeddings)\n",
        "        # Apply ReLU activation function\n",
        "        cnn_output = F.relu(cnn_output)\n",
        "        # Flatten the output\n",
        "        cnn_output = cnn_output.view(cnn_output.size(0), -1)\n",
        "        # Apply linear layer\n",
        "        output = self.fc(cnn_output)\n",
        "        return output"
      ],
      "metadata": {
        "id": "fKxVFQ4ChN5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the training function\n",
        "def train(model, train_loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    correct = 0.0\n",
        "    total = 0.0\n",
        "    for batch_idx, (tokens, labels) in enumerate(train_loader):\n",
        "        tokens = tokens.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(tokens)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    accuracy = correct / total\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    return avg_loss, accuracy"
      ],
      "metadata": {
        "id": "d_llEGN6hN8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the validation function\n",
        "def validate(model, val_loader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    correct = 0.0\n",
        "    total = 0.0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (tokens, labels) in enumerate(val_loader):\n",
        "            tokens = tokens.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(tokens)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = correct / total\n",
        "    avg_loss = total_loss / len(val_loader)\n",
        "    return avg_loss, accuracy\n"
      ],
      "metadata": {
        "id": "ByRG3_7rgiJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the test function\n",
        "def test(model, test_loader):\n",
        "    model.eval()\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (tokens, labels) in enumerate(test_loader):\n",
        "            tokens = tokens.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(tokens)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            y_true += labels.cpu().numpy().tolist()\n",
        "            y_pred += predicted.cpu().numpy().tolist()\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average=\"weighted\")\n",
        "    recall = recall_score(y_true, y_pred, average=\"weighted\")\n",
        "    f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
        "    return accuracy, precision, recall, f1\n"
      ],
      "metadata": {
        "id": "65YCrzvRgiUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_accuracy, test_precision, test_recall, test_f1 = test(model, test_loader)\n",
        "\n",
        "# Print the metrics\n",
        "print(\"Test Accuracy: {:.4f}\".format(test_accuracy))\n",
        "print(\"Test Precision: {:.4f}\".format(test_precision))\n",
        "print(\"Test Recall: {:.4f}\".format(test_recall))\n",
        "print(\"Test F1 Score: {:.4f}\".format(test_f1))\n"
      ],
      "metadata": {
        "id": "QEJnKCvkgibL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import praw\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Initialize the Reddit API client\n",
        "reddit = praw.Reddit(client_id='YOUR_CLIENT_ID', client_secret='YOUR_CLIENT_SECRET', user_agent='YOUR_USER_AGENT')\n",
        "\n",
        "# Define a function to extract comments from a subreddit\n",
        "def get_comments_from_subreddit(subreddit, num_comments):\n",
        "    comments = []\n",
        "    for comment in reddit.subreddit(subreddit).comments(limit=num_comments):\n",
        "        comments.append(comment.body)\n",
        "    return comments\n"
      ],
      "metadata": {
        "id": "5cdkiNl3gigt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract comments from a subreddit\n",
        "df_reddit = pd.read_csv('reddit_data.csv')  # Load Reddit data from a CSV file\n",
        "comments = df_reddit['text']\n",
        "\n",
        "# Preprocess the comments\n",
        "preprocessed_comments = preprocess_comments(comments)\n",
        "\n",
        "# Convert the preprocessed comments into tensors\n",
        "tokens = [torch.tensor([word_to_idx.get(word, 0) for word in comment]) for comment in preprocessed_comments]\n",
        "labels = torch.zeros(len(tokens), dtype=torch.long)  # Set the labels to 0, since we're not interested in sentiment polarity\n",
        "\n"
      ],
      "metadata": {
        "id": "H5hfWBjrgii8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create a test dataset and loader\n",
        "test_dataset = TextDataset(tokens, labels)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_accuracy, test_precision, test_recall, test_f1 = test(model, test_loader)\n",
        "\n"
      ],
      "metadata": {
        "id": "1vfH6v2kginC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the metrics\n",
        "print(\"Test Accuracy: {:.4f}\".format(test_accuracy))\n",
        "print(\"Test Precision: {:.4f}\".format(test_precision))\n",
        "print(\"Test Recall: {:.4f}\".format(test_recall))\n",
        "print(\"Test F1 Score: {:.4f}\".format(test_f1))"
      ],
      "metadata": {
        "id": "knhLWzbmgiqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7aIt7NStgis3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i1M4D6fhgiu4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}