{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/navrgithub/NLP_Authorship_Attribution/blob/main/LIWC_DeBERTa_CNN_task3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import DebertaTokenizer, DebertaModel\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "lOQeFuuQprEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the LIWC+DeBERTA-CNN Model\n",
        "class LIWCDebertaCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(LIWCDebertaCNN, self).__init__()\n",
        "        self.liwc_features = 100  # Number of LIWC features\n",
        "        self.deberta_hidden_size = 768  # Hidden size of DeBERTA model\n",
        "        self.conv_filters = 256  # Number of CNN filters\n",
        "        self.kernel_size = 3  # CNN kernel size\n",
        "\n",
        "        self.liwc_embedding = nn.Embedding(num_liwc_categories, self.liwc_features)\n",
        "        self.deberta = DebertaModel.from_pretrained('microsoft/deberta-base')\n",
        "        self.cnn = nn.Conv1d(self.liwc_features + self.deberta_hidden_size, self.conv_filters, self.kernel_size)\n",
        "        self.fc = nn.Linear(self.conv_filters, num_classes)\n",
        "\n",
        "    def forward(self, liwc_inputs, deberta_inputs):\n",
        "        liwc_embedded = self.liwc_embedding(liwc_inputs)\n",
        "        deberta_outputs = self.deberta(**deberta_inputs).last_hidden_state\n",
        "\n",
        "        # Reshape DeBERTA outputs to match LIWC features\n",
        "        deberta_outputs = deberta_outputs.permute(0, 2, 1)\n",
        "\n",
        "        # Concatenate LIWC and DeBERTA features\n",
        "        combined_features = torch.cat((liwc_embedded, deberta_outputs), dim=2)\n",
        "\n",
        "        # Apply CNN\n",
        "        cnn_outputs = self.cnn(combined_features)\n",
        "\n",
        "        # Max pooling\n",
        "        pooled_outputs = F.max_pool1d(cnn_outputs, cnn_outputs.size(2)).squeeze(2)\n",
        "\n",
        "        # Fully connected layer\n",
        "        logits = self.fc(pooled_outputs)\n",
        "\n",
        "        return logits"
      ],
      "metadata": {
        "id": "wB9PkCbtpuBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the LIWCDebertaDataset class\n",
        "class LIWCDebertaDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_length):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        generation = self.data['Generation'].iloc[index]\n",
        "        label = self.data['Label'].iloc[index]\n",
        "\n",
        "        encoded_inputs = self.tokenizer(generation, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
        "        input_ids = encoded_inputs['input_ids'].squeeze(0)\n",
        "        attention_mask = encoded_inputs['attention_mask'].squeeze(0)\n",
        "\n",
        "        return {'input_ids': input_ids, 'attention_mask': attention_mask, 'label': label}"
      ],
      "metadata": {
        "id": "Yka737IwpvgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the data\n",
        "df = pd.read_csv('final_task3_data.csv')\n",
        "\n",
        "# Split the data into train and test sets\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "huomxLARpyaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the DeBERTA tokenizer\n",
        "tokenizer = DebertaTokenizer.from_pretrained('microsoft/deberta-base')"
      ],
      "metadata": {
        "id": "TnBJIR4fp0Lu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define hyperparameters\n",
        "batch_size = 16\n",
        "num_epochs = 10\n",
        "learning_rate = 1e-4\n",
        "num_classes = 2  # Number of label classes"
      ],
      "metadata": {
        "id": "MciKaPHCp0Iw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create LIWCDebertaDataset instances\n",
        "train_dataset = LIWCDebertaDataset(train_df, tokenizer, max_length=128)\n",
        "test_dataset = LIWCDebertaDataset(test_df, tokenizer, max_length=128)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "uIA3HXhYp5BQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize LIWCDebertaCNN model\n",
        "model = LIWCDebertaCNN(num_classes)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "kb66UVnKp4-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "  model.train()\n",
        "  running_loss = 0.0\n",
        "  correct_predictions = 0\n",
        "  for batch in train_loader:\n",
        "    input_ids = batch['input_ids']\n",
        "    attention_mask = batch['attention_mask']\n",
        "    labels = batch['label']\n",
        "\n",
        "    # Zero the gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass\n",
        "    logits = model(input_ids, attention_mask)\n",
        "    loss = criterion(logits, labels)\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Update statistics\n",
        "    running_loss += loss.item() * input_ids.size(0)\n",
        "    _, predictions = torch.max(logits, dim=1)\n",
        "    correct_predictions += torch.sum(predictions == labels).item()\n",
        "\n",
        "    # Calculate epoch statistics\n",
        "    epoch_loss = running_loss / len(train_dataset)\n",
        "    epoch_accuracy = correct_predictions / len(train_dataset)\n",
        "\n",
        "    # Evaluation on test set\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    test_correct_predictions = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for batch in test_loader:\n",
        "        input_ids = batch['input_ids']\n",
        "        attention_mask = batch['attention_mask']\n",
        "        labels = batch['label']\n",
        "\n",
        "        logits = model(input_ids, attention_mask)\n",
        "        loss = criterion(logits, labels)\n",
        "\n",
        "        test_loss += loss.item() * input_ids.size(0)\n",
        "        _, predictions = torch.max(logits, dim=1)\n",
        "        test_correct_predictions += torch.sum(predictions == labels).item()\n",
        "\n",
        "    # Calculate test set statistics\n",
        "    test_loss /= len(test_dataset)\n",
        "    test_accuracy = test_correct_predictions / len(test_dataset)\n",
        "\n",
        "    # Print epoch results\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs} | '\n",
        "          f'Training Loss: {epoch_loss:.4f} | Training Accuracy: {epoch_accuracy:.4f} | '\n",
        "          f'Test Loss: {test_loss:.4f} | Test Accuracy: {test_accuracy:.4f}')\n"
      ],
      "metadata": {
        "id": "g2dmh77NpBbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "torch.save(model.state_dict(), 'liwc_deberta_cnn_model.pth')"
      ],
      "metadata": {
        "id": "UIkS2BgGpBYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Evaluation on test set\n",
        "model.eval()\n",
        "predictions = []\n",
        "true_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids = batch['input_ids']\n",
        "        attention_mask = batch['attention_mask']\n",
        "        labels = batch['label']\n",
        "\n",
        "        logits = model(input_ids, attention_mask)\n",
        "        _, batch_predictions = torch.max(logits, dim=1)\n",
        "\n",
        "        predictions.extend(batch_predictions.tolist())\n",
        "        true_labels.extend(labels.tolist())\n",
        "\n",
        "# Calculate metrics\n",
        "f1 = f1_score(true_labels, predictions, average='weighted')\n",
        "precision = precision_score(true_labels, predictions, average='weighted')\n",
        "recall = recall_score(true_labels, predictions, average='weighted')"
      ],
      "metadata": {
        "id": "cSgi-9Hzqdol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the metrics\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')"
      ],
      "metadata": {
        "id": "npKZmyAJqhTM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}